{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# üî¨ Stage 1: Baseline Embedding Detector\n",
                "\n",
                "## System detekcji deepfake z CLIP + Vector Database\n",
                "\n",
                "**Podej≈õcie:**\n",
                "1. U≈ºyj pretrained CLIP (bez fine-tuningu)\n",
                "2. Zbuduj bazƒô wektorowƒÖ z known real/fake\n",
                "3. Klasyfikuj przez k-NN similarity\n",
                "\n",
                "**Oczekiwana accuracy:** ~65-75%\n",
                "\n",
                "---\n",
                "\n",
                "## üìä GPU Setup\n",
                "**Runtime ‚Üí Change runtime type ‚Üí GPU (T4)**"
            ],
            "metadata": {
                "id": "header"
            }
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "check_gpu"
            },
            "outputs": [],
            "source": [
                "# Sprawd≈∫ GPU\n",
                "import torch\n",
                "print(f\"PyTorch: {torch.__version__}\")\n",
                "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 1Ô∏è‚É£ Clone Repository"
            ],
            "metadata": {
                "id": "clone"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Sklonuj repo\n",
                "!git clone https://github.com/kordin33/DeepFake.git\n",
                "%cd DeepFake\n",
                "!ls -la"
            ],
            "metadata": {
                "id": "clone_repo"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 2Ô∏è‚É£ Install Dependencies"
            ],
            "metadata": {
                "id": "install"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Instaluj CLIP i zale≈ºno≈õci\n",
                "!pip install -q git+https://github.com/openai/CLIP.git\n",
                "!pip install -q scikit-learn tqdm matplotlib seaborn\n",
                "!pip install -q umap-learn  # dla wizualizacji UMAP\n",
                "\n",
                "print(\"\\n‚úÖ Dependencies installed!\")"
            ],
            "metadata": {
                "id": "install_deps"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 3Ô∏è‚É£ Prepare Data"
            ],
            "metadata": {
                "id": "data"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Pobierz i przygotuj dane z HuggingFace\n",
                "# U≈ºyj mniejszego zbioru do szybkiego testu\n",
                "\n",
                "MAX_TRAIN_PER_CLASS = 2000  # Mo≈ºna zwiƒôkszyƒá\n",
                "MAX_TEST_PER_CLASS = 500\n",
                "\n",
                "!python efficientnet_b0_deepfake.py --prepare --data-root ./data \\\n",
                "    --max-per-class-a {MAX_TRAIN_PER_CLASS} \\\n",
                "    --max-per-class-b {MAX_TEST_PER_CLASS}"
            ],
            "metadata": {
                "id": "download_data"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Sprawd≈∫ strukturƒô danych\n",
                "from pathlib import Path\n",
                "\n",
                "data_root = Path(\"./data\")\n",
                "for folder in data_root.rglob(\"*\"):\n",
                "    if folder.is_dir() and (folder / \"fake\").exists():\n",
                "        fake_count = len(list((folder / \"fake\").glob(\"*\")))\n",
                "        real_count = len(list((folder / \"real\").glob(\"*\")))\n",
                "        print(f\"{folder}: fake={fake_count}, real={real_count}\")"
            ],
            "metadata": {
                "id": "check_data"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 4Ô∏è‚É£ Initialize Stage 1 Detector"
            ],
            "metadata": {
                "id": "init"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import sys\n",
                "sys.path.insert(0, '.')\n",
                "\n",
                "from deepfake_research.embeddings.stage1_baseline import (\n",
                "    Stage1BaselineDetector,\n",
                "    Stage1Config,\n",
                "    run_stage1_experiment,\n",
                ")\n",
                "from deepfake_research.embeddings.visualization import EmbeddingVisualizer\n",
                "\n",
                "# Konfiguracja\n",
                "config = Stage1Config(\n",
                "    encoder_name=\"clip\",\n",
                "    encoder_variant=\"ViT-B/32\",  # Mo≈ºesz zmieniƒá na \"ViT-L/14\" dla lepszych wynik√≥w\n",
                "    k_neighbors=10,\n",
                "    db_backend=\"numpy\",\n",
                "    device=\"cuda\",\n",
                ")\n",
                "\n",
                "# Inicjalizacja detektora\n",
                "detector = Stage1BaselineDetector(config)"
            ],
            "metadata": {
                "id": "init_detector"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 5Ô∏è‚É£ Build Vector Database (Training)"
            ],
            "metadata": {
                "id": "train"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Zbuduj bazƒô wektorowƒÖ z danych treningowych\n",
                "TRAIN_REAL = \"./data/A_standardized_224/train/real\"\n",
                "TRAIN_FAKE = \"./data/A_standardized_224/train/fake\"\n",
                "\n",
                "train_stats = detector.fit_from_folder(\n",
                "    real_folder=TRAIN_REAL,\n",
                "    fake_folder=TRAIN_FAKE,\n",
                "    max_images=2000,  # Mo≈ºesz zwiƒôkszyƒá\n",
                "    batch_size=64,\n",
                ")\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"DATABASE STATISTICS\")\n",
                "print(\"=\"*50)\n",
                "for key, value in train_stats.items():\n",
                "    print(f\"  {key}: {value}\")"
            ],
            "metadata": {
                "id": "build_db"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 6Ô∏è‚É£ Evaluate on Test Set A (In-Domain)"
            ],
            "metadata": {
                "id": "eval_a"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Test na Dataset A (ten sam domain co train)\n",
                "TEST_A_REAL = \"./data/A_standardized_224/test_A/real\"\n",
                "TEST_A_FAKE = \"./data/A_standardized_224/test_A/fake\"\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"EVALUATION - DATASET A (In-Domain)\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "results_A = detector.evaluate_from_folder(\n",
                "    real_folder=TEST_A_REAL,\n",
                "    fake_folder=TEST_A_FAKE,\n",
                "    max_images=500,\n",
                ")"
            ],
            "metadata": {
                "id": "eval_a_cell"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 7Ô∏è‚É£ Evaluate on Test Set B (Cross-Domain)"
            ],
            "metadata": {
                "id": "eval_b"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Test na Dataset B (inny domain - sprawdzamy generalizacjƒô!)\n",
                "TEST_B_REAL = \"./data/B_standardized_224/test_B/real\"\n",
                "TEST_B_FAKE = \"./data/B_standardized_224/test_B/fake\"\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"EVALUATION - DATASET B (Cross-Domain)\")\n",
                "print(\"=\"*50)\n",
                "\n",
                "results_B = detector.evaluate_from_folder(\n",
                "    real_folder=TEST_B_REAL,\n",
                "    fake_folder=TEST_B_FAKE,\n",
                "    max_images=500,\n",
                ")"
            ],
            "metadata": {
                "id": "eval_b_cell"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 8Ô∏è‚É£ üìä Visualization - t-SNE & Cluster Analysis"
            ],
            "metadata": {
                "id": "viz"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Pobierz wszystkie embeddingi z bazy\n",
                "embeddings, labels = detector.db.get_all_embeddings()\n",
                "\n",
                "print(f\"Embeddings shape: {embeddings.shape}\")\n",
                "print(f\"Labels: {len(labels)} ({sum(l == 'real' for l in labels)} real, {sum(l == 'fake' for l in labels)} fake)\")"
            ],
            "metadata": {
                "id": "get_emb"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# t-SNE Visualization\n",
                "visualizer = EmbeddingVisualizer(figsize=(12, 10))\n",
                "\n",
                "visualizer.plot_tsne(\n",
                "    embeddings=embeddings,\n",
                "    labels=labels,\n",
                "    title=\"t-SNE: CLIP Embeddings (Real vs Fake)\",\n",
                "    save_path=\"stage1_tsne.png\",\n",
                ")"
            ],
            "metadata": {
                "id": "tsne"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# UMAP Visualization (often better than t-SNE)\n",
                "visualizer.plot_umap(\n",
                "    embeddings=embeddings,\n",
                "    labels=labels,\n",
                "    title=\"UMAP: CLIP Embeddings (Real vs Fake)\",\n",
                "    save_path=\"stage1_umap.png\",\n",
                ")"
            ],
            "metadata": {
                "id": "umap"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Cluster Analysis\n",
                "cluster_metrics = visualizer.plot_cluster_analysis(\n",
                "    embeddings=embeddings,\n",
                "    labels=labels,\n",
                "    title=\"Cluster Analysis: Class Separation\",\n",
                "    save_path=\"stage1_clusters.png\",\n",
                ")\n",
                "\n",
                "print(\"\\nCluster Metrics:\")\n",
                "for key, value in cluster_metrics.items():\n",
                "    print(f\"  {key}: {value:.4f}\")"
            ],
            "metadata": {
                "id": "cluster"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 9Ô∏è‚É£ Single Image Prediction Example"
            ],
            "metadata": {
                "id": "predict"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "from PIL import Image\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# We≈∫ losowy obraz testowy\n",
                "import random\n",
                "from pathlib import Path\n",
                "\n",
                "test_images = list(Path(TEST_A_FAKE).glob(\"*.jpg\"))[:5] + list(Path(TEST_A_REAL).glob(\"*.jpg\"))[:5]\n",
                "random.shuffle(test_images)\n",
                "\n",
                "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
                "\n",
                "for ax, img_path in zip(axes.flatten(), test_images):\n",
                "    img = Image.open(img_path).convert(\"RGB\")\n",
                "    result = detector.predict(img, method=\"knn\")\n",
                "    \n",
                "    # Ground truth\n",
                "    gt = \"real\" if \"real\" in str(img_path.parent) else \"fake\"\n",
                "    correct = result.prediction == gt\n",
                "    \n",
                "    ax.imshow(img)\n",
                "    ax.set_title(\n",
                "        f\"Pred: {result.prediction}\\nGT: {gt}\\nConf: {result.confidence:.2f}\",\n",
                "        color=\"green\" if correct else \"red\",\n",
                "        fontsize=9,\n",
                "    )\n",
                "    ax.axis(\"off\")\n",
                "\n",
                "plt.suptitle(\"Stage 1 Predictions (Green=Correct, Red=Wrong)\", fontsize=14)\n",
                "plt.tight_layout()\n",
                "plt.savefig(\"stage1_predictions.png\", dpi=150)\n",
                "plt.show()"
            ],
            "metadata": {
                "id": "predict_viz"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## üîü Summary & Results"
            ],
            "metadata": {
                "id": "summary"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"üìä STAGE 1 RESULTS SUMMARY\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "print(\"\\nüîß Configuration:\")\n",
                "print(f\"   Encoder: CLIP {config.encoder_variant}\")\n",
                "print(f\"   K neighbors: {config.k_neighbors}\")\n",
                "print(f\"   Database size: {detector.db.count()} embeddings\")\n",
                "\n",
                "print(\"\\nüìà Results - Dataset A (In-Domain):\")\n",
                "for method, metrics in results_A.items():\n",
                "    print(f\"   {method.upper()}: Accuracy = {metrics['accuracy']:.4f}, F1 = {metrics['f1']:.4f}\")\n",
                "\n",
                "print(\"\\nüìà Results - Dataset B (Cross-Domain):\")\n",
                "for method, metrics in results_B.items():\n",
                "    print(f\"   {method.upper()}: Accuracy = {metrics['accuracy']:.4f}, F1 = {metrics['f1']:.4f}\")\n",
                "\n",
                "print(\"\\nüìä Cluster Separation:\")\n",
                "print(f\"   Silhouette Score: {cluster_metrics['silhouette_score']:.4f}\")\n",
                "print(f\"   K-Means Accuracy: {cluster_metrics['kmeans_accuracy']:.4f}\")\n",
                "print(f\"   Separation Ratio: {cluster_metrics['separation_ratio']:.4f}\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"üí° ANALYSIS\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "best_acc_A = max(m['accuracy'] for m in results_A.values())\n",
                "best_acc_B = max(m['accuracy'] for m in results_B.values())\n",
                "\n",
                "if best_acc_A < 0.70:\n",
                "    print(\"‚ùå Low accuracy! CLIP embeddings don't separate well.\")\n",
                "    print(\"   ‚Üí Need Stage 2: Better classification algorithms\")\n",
                "    print(\"   ‚Üí Or Stage 3: LoRA fine-tuning\")\n",
                "elif best_acc_A < 0.80:\n",
                "    print(\"‚ö†Ô∏è Moderate accuracy. Baseline works, but can be improved.\")\n",
                "    print(\"   ‚Üí Proceed to Stage 2: Try SVM, MLP classifiers\")\n",
                "else:\n",
                "    print(\"‚úÖ Good accuracy! CLIP embeddings are useful.\")\n",
                "    print(\"   ‚Üí Stage 2 may still improve results\")\n",
                "\n",
                "if cluster_metrics['silhouette_score'] < 0.1:\n",
                "    print(\"\\n‚ö†Ô∏è Classes overlap significantly in embedding space.\")\n",
                "    print(\"   ‚Üí Fine-tuning (Stage 3) will likely help a lot!\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)"
            ],
            "metadata": {
                "id": "summary_cell"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 1Ô∏è‚É£1Ô∏è‚É£ Save Results & Model"
            ],
            "metadata": {
                "id": "save"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Zapisz detektor\n",
                "detector.save(\"./stage1_detector\")\n",
                "\n",
                "# Zapisz wyniki do JSON\n",
                "import json\n",
                "\n",
                "results_summary = {\n",
                "    \"config\": {\n",
                "        \"encoder_variant\": config.encoder_variant,\n",
                "        \"k_neighbors\": config.k_neighbors,\n",
                "    },\n",
                "    \"results_A\": results_A,\n",
                "    \"results_B\": results_B,\n",
                "    \"cluster_metrics\": cluster_metrics,\n",
                "}\n",
                "\n",
                "with open(\"stage1_results.json\", \"w\") as f:\n",
                "    json.dump(results_summary, f, indent=2, default=str)\n",
                "\n",
                "print(\"\\n‚úÖ Results saved to stage1_results.json\")"
            ],
            "metadata": {
                "id": "save_cell"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "## 1Ô∏è‚É£2Ô∏è‚É£ Save to Google Drive"
            ],
            "metadata": {
                "id": "drive"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "from google.colab import drive\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "import shutil\n",
                "from datetime import datetime\n",
                "\n",
                "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
                "dest = f\"/content/drive/MyDrive/deepfake_stage1_{timestamp}\"\n",
                "\n",
                "# Kopiuj wyniki\n",
                "import os\n",
                "os.makedirs(dest, exist_ok=True)\n",
                "\n",
                "for f in [\"stage1_tsne.png\", \"stage1_umap.png\", \"stage1_clusters.png\", \n",
                "          \"stage1_predictions.png\", \"stage1_results.json\"]:\n",
                "    if os.path.exists(f):\n",
                "        shutil.copy(f, dest)\n",
                "\n",
                "shutil.copytree(\"./stage1_detector\", f\"{dest}/detector\", dirs_exist_ok=True)\n",
                "\n",
                "print(f\"\\n‚úÖ Saved to: {dest}\")"
            ],
            "metadata": {
                "id": "drive_cell"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "\n",
                "# üéØ Next Steps\n",
                "\n",
                "## If accuracy < 75%:\n",
                "‚Üí **Stage 2**: Try better classifiers (SVM, MLP, XGBoost) on embeddings\n",
                "\n",
                "## If accuracy 75-85%:\n",
                "‚Üí **Stage 3**: LoRA fine-tuning on CLIP\n",
                "\n",
                "## If you want better generalization:\n",
                "‚Üí **Stage 4**: Add frequency domain features (FFT)\n",
                "\n",
                "---\n",
                "\n",
                "**Report your results and we'll proceed to the next stage!**"
            ],
            "metadata": {
                "id": "next"
            }
        }
    ]
}