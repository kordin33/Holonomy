# ğŸš€ Jak UruchomiÄ‡ na Google Colab z GitHub

## Krok 1: WrzuÄ‡ projekt na GitHub

### Opcja A: Przez Git (zalecane)
```bash
cd "e:\AI iNflu\Kenczuks"

# Inicjalizuj repo (jeÅ›li nie ma)
git init

# Dodaj wszystkie pliki
git add .

# Commit
git commit -m "Deepfake Detection Research Project"

# Dodaj remote (zmieÅ„ na swoje repo!)
git remote add origin https://github.com/TWOJ-USERNAME/Kenczuks.git

# Push
git push -u origin main
```

### Opcja B: Przez GitHub Desktop
1. OtwÃ³rz GitHub Desktop
2. File â†’ Add Local Repository â†’ Wybierz folder Kenczuks
3. Commit wszystkie zmiany
4. Push to GitHub

---

## Krok 2: OtwÃ³rz Colab

1. IdÅº do [Google Colab](https://colab.research.google.com/)
2. File â†’ Upload Notebook
3. WrzuÄ‡ plik `Deepfake_Detection_Colab.ipynb` z tego folderu

**LUB** (jeÅ›li masz juÅ¼ notebook na GitHub):

1. IdÅº do Colab
2. File â†’ Open Notebook â†’ GitHub
3. Wklej URL do swojego repo

---

## Krok 3: WÅ‚Ä…cz GPU

1. W Colab: **Runtime â†’ Change runtime type**
2. Hardware accelerator: **GPU**
3. GPU type: **T4** (lub lepsze jak V100, A100 jeÅ›li masz Pro)
4. Save

---

## Krok 4: Uruchom komÃ³rki po kolei

1. **SprawdÅº GPU** - upewnij siÄ™ Å¼e masz GPU
2. **Sklonuj repo** - zmieÅ„ URL na swoje repo!
3. **Zainstaluj zaleÅ¼noÅ›ci**
4. **Quick test** - sprawdÅº czy wszystko dziaÅ‚a
5. **Przygotuj dane** - z Drive lub HuggingFace
6. **Uruchom eksperymenty**
7. **Zapisz wyniki na Drive**

---

## ğŸ“Š Szacowany Czas na T4 GPU

| Eksperyment | Opis | Czas |
|-------------|------|------|
| `--experiment baseline --epochs 5` | Szybki test | ~15 min |
| `--experiment baseline --epochs 20` | EfficientNet + ViT | ~1 godz |
| `--experiment advanced --epochs 20` | + Frequency + Attention | ~2 godz |
| `--experiment all --epochs 20` | Wszystkie 6 modeli | ~3-4 godz |
| `--experiment ultimate --epochs 25` | Ultimate model | ~1.5 godz |

---

## âš¡ Optymalizacje CUDA (automatyczne)

Projekt uÅ¼ywa:
- âœ… **torch.compile()** - 20-40% speedup (PyTorch 2.0+)
- âœ… **cuDNN Benchmark** - 10-20% speedup
- âœ… **TensorFloat-32** - 3x szybszy matmul na Ampere GPUs
- âœ… **Mixed Precision (AMP)** - 2x szybciej, mniej VRAM
- âœ… **Flash Attention** - automatyczne dla ViT

---

## ğŸ”§ Troubleshooting

### "CUDA out of memory"
Zmniejsz batch size:
```bash
python run_experiments.py --experiment all --epochs 20 --batch-size 16
```

### "Module not found"
Upewnij siÄ™ Å¼e jesteÅ› w folderze projektu:
```python
%cd /content/Kenczuks
```

### Colab siÄ™ zresetowaÅ‚
- Zapisuj wyniki na Google Drive regularnie!
- UÅ¼yj komÃ³rki "Zapisz wyniki na Drive"

### Wolny download danych
UÅ¼yj mniejszego datasetu:
```bash
python efficientnet_b0_deepfake.py --prepare --max-per-class-a 1000
```

---

## ğŸ“ Struktura WynikÃ³w na Drive

Po zapisaniu na Drive:
```
/content/drive/MyDrive/deepfake_results_YYYYMMDD_HHMMSS/
â”œâ”€â”€ benchmark/
â”‚   â”œâ”€â”€ full_benchmark.json      # Wszystkie metryki
â”‚   â””â”€â”€ BENCHMARK_REPORT.md      # Raport markdown
â”œâ”€â”€ cross_dataset_heatmap.png    # Wizualizacja
â”œâ”€â”€ model_comparison.png         # PorÃ³wnanie modeli
â””â”€â”€ [model_name]/
    â”œâ”€â”€ [model_name]_best.pth    # Wagi najlepszego modelu
    â””â”€â”€ [model_name]_history.json # Historia treningu
```

---

## ğŸ¯ Rekomendowany Workflow

1. **Pierwszy raz:** `--experiment baseline --epochs 5` (szybki test)
2. **JeÅ›li dziaÅ‚a:** `--experiment all --epochs 10` (porÃ³wnanie)
3. **PeÅ‚ny benchmark:** `--experiment all --epochs 20`
4. **Najlepszy model:** `--experiment ultimate --epochs 30 --use-sbi`

---

*Powodzenia! ğŸš€*
