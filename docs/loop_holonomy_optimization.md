# âš¡ Optymalizacja Loop Holonomy przed poÅ‚Ä…czeniem z ViT-L/14 + SVM

## ðŸŽ¯ Cel
MaksymalizowaÄ‡ moc predykcyjnÄ… Loop Holonomy PRZED dodaniem do RGB embeddings.

---

## ðŸ“Š Obecny Stan (Baseline)
- **8 pÄ™tli** (rÄ™cznie wybrane)
- **Silhouette**: 0.176
- **Przewidywane AUC**: 0.65-0.72
- **Wymiary**: 8D (jedna wartoÅ›Ä‡ holonomii per pÄ™tla)

---

## ðŸ”§ STRATEGIA 1: Optymalizacja PÄ™tli (Loops)

### 1.1 **Systematyczne przeszukiwanie przestrzeni pÄ™tli**

**Parametry do optymalizacji:**
- DÅ‚ugoÅ›Ä‡ pÄ™tli: 2, 3, 4, 5, 6 transformacji
- Typ transformacji: JPEG, blur, scale, noise
- KolejnoÅ›Ä‡: iteracyjne vs alternating
- IntensywnoÅ›Ä‡: gentle vs aggressive

**PrzykÅ‚ady do przetestowania:**

```python
# KrÃ³tkie, agresywne
['jpeg_50', 'scale_0.5', 'blur_1.0']

# DÅ‚ugie, stopniowane
['jpeg_90', 'jpeg_80', 'jpeg_70', 'jpeg_60', 'jpeg_50']

# Alternating compression + artifact
['jpeg_60', 'blur_0.5', 'jpeg_80', 'blur_0.3']

# Scale cascade (test mikrotekstur przy rÃ³Å¼nych skalach)
['scale_0.5', 'scale_0.75', 'scale_0.9', 'scale_0.75', 'scale_0.5']

# Mixed degradations
['noise_0.01', 'jpeg_70', 'blur_0.5', 'scale_0.75']
```

**Metoda:**
1. Generuj N=100 rÃ³Å¼nych pÄ™tli (random + rÄ™czne)
2. Testuj kaÅ¼dÄ… na maÅ‚ej prÃ³bce (n=200)
3. Oblicz AUC dla kaÅ¼dej pÄ™tli
4. Wybierz top-K (K=10-15) najlepszych
5. Re-testuj na peÅ‚nym datasecie

**Implementacja:**
```python
from sklearn.metrics import roc_auc_score

def optimize_loops(encoder, images, labels, n_candidates=100):
    candidate_loops = generate_random_loops(n_candidates)
    
    scores = []
    for loop in candidate_loops:
        hol_features = extract_holonomy_for_loop(encoder, images, loop)
        auc = roc_auc_score(labels, hol_features)
        scores.append((loop, auc))
    
    # Sort by AUC
    scores.sort(key=lambda x: x[1], reverse=True)
    return scores[:15]  # Top 15
```

---

## ðŸ”§ STRATEGIA 2: Feature Engineering

### 2.1 **Dodatkowe cechy z pÄ™tli**

Zamiast tylko `H(x) = ||e(T_nâˆ˜...âˆ˜T_1(x)) - e(x)||`, ekstraktuj:

**A) Trajektoria embedding w pÄ™tli:**
```
z_0 = e(x)
z_1 = e(T_1(x))
z_2 = e(T_2(T_1(x)))
...
z_n = e(T_n(...))

Cechy:
- Cumulative distance: sum(||z_i - z_{i-1}||)
- Max deviation: max_i(||z_i - z_0||)
- Path curvature: mierzy "zakrÄ™ty" w trajektorii
- Monotonicity: czy odlegÅ‚oÅ›Ä‡ roÅ›nie monotonicznie
```

**B) Momentum cechy:**
```python
def extract_trajectory_features(encoder, image, loop):
    embeddings = compute_trajectory(encoder, image, loop)
    
    features = []
    
    # 1. Holonomy (baseline)
    holonomy = np.linalg.norm(embeddings[-1] - embeddings[0])
    features.append(holonomy)
    
    # 2. Total path length
    path_length = sum(np.linalg.norm(embeddings[i] - embeddings[i-1]) 
                      for i in range(1, len(embeddings)))
    features.append(path_length)
    
    # 3. Max deviation from origin
    max_dev = max(np.linalg.norm(e - embeddings[0]) 
                  for e in embeddings)
    features.append(max_dev)
    
    # 4. Curvature (sum of angles)
    curvature = 0
    for i in range(1, len(embeddings)-1):
        v1 = embeddings[i] - embeddings[i-1]
        v2 = embeddings[i+1] - embeddings[i]
        angle = np.arccos(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-8))
        curvature += angle
    features.append(curvature)
    
    # 5. Monotonicity score
    distances = [np.linalg.norm(e - embeddings[0]) for e in embeddings]
    monotonic = 1 if all(distances[i] <= distances[i+1] for i in range(len(distances)-1)) else 0
    features.append(monotonic)
    
    return np.array(features)
```

**Wymiary:**
- Baseline: 8 pÄ™tli Ã— 1 cecha = 8D
- Enhanced: 8 pÄ™tli Ã— 5 cech = **40D** âœ…

---

### 2.2 **Cross-loop interactions**

**Idea:** RÃ³Å¼ne pÄ™tle mogÄ… mieÄ‡ komplementarne sygnaÅ‚y.

```python
# Dla kaÅ¼dej pary pÄ™tli (i, j):
correlation = np.corrcoef(holonomy_i, holonomy_j)[0, 1]
ratio = holonomy_i / (holonomy_j + epsilon)
difference = abs(holonomy_i - holonomy_j)

# Feature vector: [h_1, h_2, ..., h_8, corr_12, corr_13, ..., ratio_12, ...]
# Wymiary: 8 + C(8,2) + C(8,2) = 8 + 28 + 28 = 64D
```

---

## ðŸ”§ STRATEGIA 3: Normalizacja i Skalowanie

### 3.1 **Per-image normalization**

RÃ³Å¼ne obrazy majÄ… rÃ³Å¼ne "baseline" holonomie. Normalizuj wzglÄ™dem prostej degradacji:

```python
def normalize_holonomy(encoder, image, loop):
    # Holonomy dla testowanej pÄ™tli
    H_loop = compute_holonomy(encoder, image, loop)
    
    # Baseline: identity transformation
    H_baseline = compute_holonomy(encoder, image, ['identity', 'identity'])
    
    # Normalized
    H_norm = H_loop / (H_baseline + epsilon)
    
    return H_norm
```

### 3.2 **Feature scaling**

Testuj rÃ³Å¼ne metody:
- StandardScaler (z-score)
- MinMaxScaler ([0, 1])
- RobustScaler (mediana + IQR)
- PowerTransformer (Yeo-Johnson)
- QuantileTransformer (uniform distribution)

```python
from sklearn.preprocessing import StandardScaler, PowerTransformer

# Test rÃ³Å¼nych scalerÃ³w
scalers = {
    'standard': StandardScaler(),
    'power': PowerTransformer(),
    # ...
}

for name, scaler in scalers.items():
    features_scaled = scaler.fit_transform(features)
    auc = evaluate(features_scaled, labels)
    print(f"{name}: AUC={auc:.4f}")
```

---

## ðŸ”§ STRATEGIA 4: Selekcja Cech (Feature Selection)

### 4.1 **UsuniÄ™cie redundantnych pÄ™tli**

JeÅ›li 2 pÄ™tle dajÄ… bardzo podobne wyniki, usuÅ„ jednÄ…:

```python
from sklearn.feature_selection import SelectKBest, f_classif

# ANOVA F-test
selector = SelectKBest(f_classif, k=6)  # wybierz 6 najlepszych z 8
features_selected = selector.fit_transform(features, labels)

# KtÃ³re pÄ™tle zostaÅ‚y?
selected_indices = selector.get_support(indices=True)
print(f"Selected loops: {selected_indices}")
```

### 4.2 **PCA/LDA compression**

JeÅ›li mamy 40D po feature engineering, zredukuj do najwaÅ¼niejszych wymiarÃ³w:

```python
from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

# PCA (unsupervised)
pca = PCA(n_components=10)
features_pca = pca.fit_transform(features_40d)

# LDA (supervised - najlepsze dla klasyfikacji!)
lda = LinearDiscriminantAnalysis(n_components=1)  # Max = n_classes - 1
features_lda = lda.fit_transform(features_40d, labels)
```

---

## ðŸ”§ STRATEGIA 5: Ensemble Loops

### 5.1 **Bagging loops**

Zamiast wybieraÄ‡ top-8 pÄ™tli, uÅ¼yj wielu zestawÃ³w:

```python
# 5 zestawÃ³w po 8 pÄ™tli
loop_ensembles = [
    [loops_1_8],    # Top aggressive
    [loops_9_16],   # Top gentle
    [loops_17_24],  # Top mixed
    [loops_25_32],  # Top long
    [loops_33_40],  # Top short
]

# Dla kaÅ¼dego obrazu: 5 Ã— 8 = 40D
# Lub Å›rednia: mean([h1, h2, h3, h4, h5]) = 8D ale stabilniejsze
```

---

## ðŸ”§ STRATEGIA 6: Adaptacyjne PÄ™tle

### 6.1 **Image-specific loops**

RÃ³Å¼ne obrazy mogÄ… potrzebowaÄ‡ rÃ³Å¼nych pÄ™tli:

```python
def adaptive_loops(encoder, image):
    # Quick test: ktÃ³re pÄ™tle dajÄ… najwiÄ™kszÄ… holonomiÄ™ dla TEGO obrazu?
    holonomies = []
    for loop in candidate_loops:
        h = compute_holonomy(encoder, image, loop)
        holonomies.append((loop, h))
    
    # Wybierz top-3 dla tego obrazu
    holonomies.sort(key=lambda x: x[1], reverse=True)
    selected = holonomies[:3]
    
    # Feature: holonomie z top-3 pÄ™tli
    return np.array([h for _, h in selected])
```

---

## ðŸ”§ STRATEGIA 7: Multi-Scale Holonomy

### 7.1 **Testuj w rÃ³Å¼nych rozdzielczoÅ›ciach**

```python
def multiscale_holonomy(encoder, image, loop):
    holonomies = []
    
    for size in [112, 224, 448]:
        img_resized = image.resize((size, size))
        h = compute_holonomy(encoder, img_resized, loop)
        holonomies.append(h)
    
    # Features: [H_112, H_224, H_448]
    # + derived: std, max-min, ratios
    return holonomies
```

---

## ðŸŽ¯ PLAN DZIAÅANIA (Priorytet)

### **FAZA 1: Quick Wins** (1-2h implementacji)
1. âœ… **Feature Engineering** (Strategia 2.1)
   - Dodaj: path_length, max_dev, curvature
   - 8 pÄ™tli Ã— 5 cech = 40D
   - Oczekiwany boost: +5-10% AUC

2. âœ… **Normalizacja** (Strategia 3.1)
   - Per-image normalization
   - Oczekiwany boost: +2-5% AUC

3. âœ… **Feature Scaling** (Strategia 3.2)
   - Testuj PowerTransformer
   - Oczekiwany boost: +1-3% AUC

### **FAZA 2: Loop Optimization** (2-4h)
4. âœ… **Systematyczne przeszukiwanie** (Strategia 1.1)
   - Generuj 100 kandydatÃ³w
   - Testuj na prÃ³bce
   - Wybierz top-15
   - Oczekiwany boost: +5-15% AUC

### **FAZA 3: Advanced** (4-8h)
5. ðŸ”¬ **Cross-loop interactions** (Strategia 2.2)
6. ðŸ”¬ **LDA compression** (Strategia 4.2)
7. ðŸ”¬ **Ensemble loops** (Strategia 5)

---

## ðŸ’¡ OCZEKIWANE WYNIKI

**Baseline (obecny):**
- AUC standalone: ~0.65-0.72
- Wymiary: 8D

**Po optymalizacji (Faza 1-2):**
- AUC standalone: ~**0.75-0.82** âœ…
- Wymiary: 40D (z moÅ¼liwoÅ›ciÄ… redukcji do 10-15D przez LDA)

**Impact na RGB+Holonomy:**
- Baseline RGB: ~95% accuracy
- RGB + Holonomy (przed optym): ~96-97%
- RGB + Holonomy (po optym): ~**97-98%** ðŸš€

---

## ðŸ› ï¸ IMPLEMENTACJA

StworzÄ™ `optimize_loop_holonomy.py` ktÃ³ry:
1. Implementuje wszystkie strategie
2. Testuje systematycznie
3. Wybiera najlepszÄ… konfiguracjÄ™
4. Zapisuje optymalny extractor

**Uruchomimy to ZARAZ po otrzymaniu wynikÃ³w current analysis!**
